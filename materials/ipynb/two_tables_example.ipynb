{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating on all pairs of rows in two datasets\n",
    "\n",
    "A quick note about operating on all pairs of rows in two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "np.set_printoptions(precision = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rowid       date cat       num         a\n",
      "0      1 2018-01-28   a -4.275534 -3.946133\n",
      "1      2 2018-01-16   e -4.663584 -6.819080\n",
      "2      3 2018-01-22   d -6.265544 -9.200082\n",
      "3      4 2018-02-06   b -5.355482 -5.624009\n",
      "4      5 2018-02-13   b -3.667751  6.211971\n",
      "   rowid       date cat       num         b\n",
      "0      1 2018-01-21   c -0.120782 -3.838105\n",
      "1      2 2018-02-09   d  5.024004  0.170951\n",
      "2      3 2018-01-20   d -6.507004 -8.967068\n",
      "3      4 2018-01-03   c  6.967848  1.291397\n",
      "4      5 2018-02-05   a  7.296677 -7.570396\n",
      "5      6 2018-01-31   c -9.162854  7.856728\n",
      "6      7 2018-01-29   d -3.656357 -9.707455\n",
      "7      8 2018-01-05   b -9.725001  5.662422\n",
      "8      9 2018-01-02   c -5.219485 -8.200773\n",
      "9     10 2018-02-09   b  4.129892  0.383800\n"
     ]
    }
   ],
   "source": [
    "# import data from CSV files\n",
    "# these are the dataframes generated from the R version of this notebook\n",
    "df1 = pd.read_csv('data/two_tables_df1.csv',\n",
    "                       dtype={'cat': np.str},\n",
    "                      parse_dates=['date'])\n",
    "df2 = pd.read_csv('data/two_tables_df2.csv',\n",
    "                      dtype={'cat': np.str},\n",
    "                      parse_dates=['date'])\n",
    "\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity functions\n",
    "\n",
    "We will define a similarity function between rows of the two dataframes. For dates we will compute the squared difference in days between dates. For numeric values we also calculate the squared difference $d$. In both cases we use transformation $\\exp{-d}$ to turn difference $d$ into a similarity. For the categorical attribute, we set similarity equal to 10 if values are equal, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define attribute similarity functions\n",
    "\n",
    "# convert a distance to a similarity\n",
    "def diff_to_similarity(d):\n",
    "    return np.exp(-d)\n",
    "\n",
    "# numeric similarity\n",
    "def num_similarity(v1, v2):\n",
    "    d = (v1-v2)**2\n",
    "    return diff_to_similarity(d)\n",
    "\n",
    "# date similarity: convert time difference to\n",
    "# numeric in 'days' units, then compute\n",
    "# numeric similarity\n",
    "def date_similarity(v1, v2):\n",
    "    d = ((v1 - v2) / datetime.timedelta(days=1))**2\n",
    "    return diff_to_similarity(d)\n",
    "\n",
    "# categorical similarity\n",
    "def cat_similarity(v1, v2):\n",
    "    return 10 if v1 == v2 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a similarity matrix\n",
    "\n",
    "We create a similarity matrix and iterate over rows of the two tables to fill in values of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00e+00, 0.00e+00, 1.00e-02, 0.00e+00, 1.00e+01, 0.00e+00,\n",
       "        1.05e+00, 0.00e+00, 4.10e-01, 0.00e+00],\n",
       "       [0.00e+00, 0.00e+00, 3.00e-02, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        3.60e-01, 0.00e+00, 7.30e-01, 0.00e+00],\n",
       "       [3.70e-01, 1.00e+01, 1.10e+01, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        1.00e+01, 0.00e+00, 3.30e-01, 0.00e+00],\n",
       "       [0.00e+00, 0.00e+00, 2.70e-01, 0.00e+00, 3.70e-01, 0.00e+00,\n",
       "        6.00e-02, 1.00e+01, 9.80e-01, 1.00e+01],\n",
       "       [0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00, 0.00e+00,\n",
       "        1.00e+00, 1.00e+01, 9.00e-02, 1.00e+01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# allocate similarity matrix\n",
    "sim_matrix = np.empty((len(df1), len(df2)))\n",
    "\n",
    "# fill similarity matrix\n",
    "for i in range(len(df1)):\n",
    "    for j in range(len(df2)):\n",
    "        s = date_similarity(df1.loc[i,'date'], df2.loc[j,'date'])\n",
    "        s += cat_similarity(df1.loc[i,'cat'], df2.loc[j,'cat'])\n",
    "        s += num_similarity(df1.loc[i,'num'], df2.loc[j,'num'])\n",
    "        sim_matrix[i,j] = s\n",
    "        \n",
    "np.round(sim_matrix, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this similarity matrix as needed. To turn this into a tidy data frame we can use in subsequent analysis we could use something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df1_id</th>\n",
       "      <th>df2_id</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.185822e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.103921e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.678794e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.257260e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.436725e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.764395e-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.744767e-41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.234098e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.125352e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   df1_id df2_id    similarity\n",
       "0       0      0  3.185822e-08\n",
       "1       1      0  1.103921e-09\n",
       "2       2      0  3.678794e-01\n",
       "3       3      0  1.257260e-12\n",
       "4       4      0  3.436725e-06\n",
       "5       0      1  2.764395e-38\n",
       "6       1      1  1.744767e-41\n",
       "7       2      1  1.000000e+01\n",
       "8       3      1  1.234098e-04\n",
       "9       4      1  1.125352e-07"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df = (pd.DataFrame(data=sim_matrix) \n",
    "    .reset_index()\n",
    "    .rename(columns={'index': 'df1_id'})\n",
    "    .melt(id_vars = 'df1_id', var_name = 'df2_id', value_name = 'similarity'))\n",
    "similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out which row in `df2` have highest similarity for each row of `df1`, we can use the groupby and construct as we have done previously. In this case, since the way pandas deals with scope and column names is a little unclear, we iterate over groups to extract the maximum similarity and create a new dataframe from that result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df1_id</th>\n",
       "      <th>df2_id</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.734162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10.961680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>10.000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    df1_id  df2_id  similarity\n",
       "20       0       4   10.000000\n",
       "41       1       8    0.734162\n",
       "12       2       2   10.961680\n",
       "48       3       9   10.000123\n",
       "49       4       9   10.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reduce_group(group):\n",
    "    i = group.similarity.idxmax()\n",
    "    return group.loc[i]\n",
    "\n",
    "pd.DataFrame([reduce_group(group) for _, group in similarity_df.groupby('df1_id')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
